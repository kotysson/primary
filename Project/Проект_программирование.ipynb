{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "(с) В.И. Фирсанова | Основы программирования на Python, НИУ ВШЭ"
      ],
      "metadata": {
        "id": "BuQHXJpp3Nli"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Используйте этот шаблон для разработки итогого проекта по курсу \"Основы программирования на Python\" 2023\n",
        "\n",
        "Курсивом выделены образцы заполнения шаблона. Эти элементы следует заменить своими данными. Также везде следует заменить код на собственный, однако не воспрещается пользоваться предложенным кодом в качестве референса"
      ],
      "metadata": {
        "id": "9Ify2duTcXmH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Название проекта: *Анализ тональности в социальных сетях*"
      ],
      "metadata": {
        "id": "ELpTHSC01XVP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## I. Введение\n",
        "   - Цели и задачи проекта\n",
        "   - Обзор проекта\n",
        "\n",
        "Цель проекта: *произвести анализ тональности данных из социальной сети ВКонтакте*\n",
        "\n",
        "Задачи:\n",
        "\n",
        "1. *Найти датасет для анализа тональности текста на платформе Kaggle*\n",
        "2. *Произвести предварительную обработку данных*\n",
        "3. *Визуализировать распределение тональности в датасете*\n",
        "4. *Выявить наиболее частотные коллокации*\n",
        "5. *Использовать алгоритм TF-IDF для создания векторных представлений текста*\n",
        "6. *Применить готовую модель для анализа тональности из библиотеки TextBLob*\n",
        "7. *Визуализировать результат обработки на матрице ошибок*\n",
        "8. *Вывести несколько правильных и ошибочных результатов, чтобы вявить слабые и сильные стороны выбранного алгоритма*\n",
        "\n",
        "*Результаты проекта могут использоваться в качестве основы для разработки модели машинного обучения для анализа тональности текста.*"
      ],
      "metadata": {
        "id": "eI0f9MiU1zZm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## II. Датасет\n",
        "   - Выбрать, описать и загрузить источник используемых данных\n",
        "\n",
        "*Датасет выгружен по ссылке [example.com](https://). Данные собирались с помощью ВКонакте API для Python.*\n"
      ],
      "metadata": {
        "id": "liGfQe7W3bep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data_path = \"/content/sentiment.csv\"\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "pDWEfecU5fR1",
        "outputId": "cffc86e9-b07e-478b-a8da-51d116d8847a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3a5654664261>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/sentiment.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/sentiment.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Какие данные описаны в датасете?\n",
        "\n",
        "Здесь можно кратко описать, из каких столбцов состоят ваши данные, какая используется разметка и т.д."
      ],
      "metadata": {
        "id": "kTUywPd4hhGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "ERK-4nQd6vyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Какие типы данных хранятся в этом датасете?\n",
        "Какой объем памяти занимают данные?\n",
        "Какие выводы можно сделать на основе этих фактов?"
      ],
      "metadata": {
        "id": "X4j_HVmj7X7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "LJxsiq947oq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Опишите свои данные, назовите средние значения, минимумы и максимумы, общее количество объектов в датасете. Сфокусируйтесь на тех данные, которые могут пригодиться вам для решения вашей задачи."
      ],
      "metadata": {
        "id": "3V3IlcJG7vMa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "   - Чистка данных (выбираете то, что подходит для ваших данных, можно использовать как нативные способы, так и библиотеки):\n",
        "     - Удаление специальных символов, URL, ненужных столбцов\n",
        "     - Токенизация\n",
        "     - Лемматизация\n",
        "     - Стемминг\n",
        "     - Удаление стоп-слов"
      ],
      "metadata": {
        "id": "wtjGTX6C5fhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Удаление пустых ячеек\n",
        "\n",
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "4sM0-Eg78bze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Удаление столбцов, которые не требуются вам для решения задачи\n",
        "\n",
        "df.drop(['3364'], axis=1, inplace=True)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "_CLSxSv78DJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Изменить названия столбцов\n",
        "\n",
        "df.rename(columns={'Facebook': 'source', 'Irrelevant': 'label', 'I mentioned on Facebook that I was struggling for motivation to go for a run the other day, which has been translated by Tom’s great auntie as ‘Hayley can’t get out of bed’ and told to his grandma, who now thinks I’m a lazy, terrible person 🤣': 'text'}, inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Zk7hVXOk8kBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Изменить типы данных\n",
        "\n",
        "df['label'] = df['label'].astype('category')\n",
        "df['label']"
      ],
      "metadata": {
        "id": "b4g_CTt28gwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Привести данные к нижнему регистру\n",
        "# Очистить данные от лищних символов с помощью регулярных выражений\n",
        "\n",
        "df['text'] = df['text'].str.lower()\n",
        "df['text'] = df['text'].str.replace('[^\\w\\s]', '', regex=True)\n",
        "df['text']"
      ],
      "metadata": {
        "id": "n8Wpo4Mv9w-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "   - Разметка (выбираете то, что подходит для ваших данных, можно использовать как нативные способы, так и библиотеки):\n",
        "     - Частеречная разметка\n",
        "     - Автоматическая разметка, необходимая для решения вашей задачи\n",
        "     - Ручная разметка, необходимая для решения вашей задачи"
      ],
      "metadata": {
        "id": "QthvsJm26nM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# частеречная разметка с NLTK\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# токенизация\n",
        "\n",
        "df['Tokens'] = df['text'].apply(nltk.word_tokenize)\n",
        "\n",
        "# частереная разметка\n",
        "\n",
        "df['POS_Tags'] = df['Tokens'].apply(nltk.pos_tag)\n",
        "\n",
        "# извлечение POS-тегов\n",
        "\n",
        "df['POS'] = df['POS_Tags'].apply(lambda tags: [pos for word, pos in tags])\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "gwgEs3Dn-SDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## III. Предварительный анализ данных\n",
        "   - Визуализируйте данные с помощью таких графиков, как:\n",
        "     - коррелограмма,\n",
        "     - гистограмма,\n",
        "     - точечная диаграмма,\n",
        "     - ящик с усами"
      ],
      "metadata": {
        "id": "DVdHNHIU5PUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# гистограмма\n",
        "\n",
        "plt.hist(df['label'], bins=20, color='skyblue', edgecolor='black')\n",
        "\n",
        "# подписать оси x, y и название гистограммы\n",
        "plt.xlabel('Количество текстов данного класса')\n",
        "plt.ylabel('Сколько раз встречается в датасете')\n",
        "plt.title('Распределение классов в датасете')\n",
        "\n",
        "# отобразить\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9ZUSaS0XBMRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# точечная диаграмма для датасета об автомобиля строится, чтобы определить наличие связи\n",
        "# между стоимостью автомобиля и количеством лошадиных сил\n",
        "\n",
        "plt.scatter(df['price'], df['horsepower'], alpha=0.5, color='green')"
      ],
      "metadata": {
        "id": "O-pmRXhZoAzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Выбросы - это данные, которые сильно отклоняются (гораздо больше или меньше) минимальных или максимальных величин\n",
        "# Например, у нас в данных самые большие значения равны 90-100, но есть одно или два значения равные 250\n",
        "# Значения, равные 250, мы назовем выбросами в данных\n",
        "# Они могут негативно влиять на статистику, например, искажать реальную картинку среднего значения\n",
        "# Чтобы их найти, можно использовать график \"ящик с усами\"\n",
        "# Этот график так назван за внешнее сходство с ящиком, у которого есть антенны\n",
        "\n",
        "# Создать ящик с усами для столбца со стоимостью автомобиля\n",
        "sns.boxplot(x=df['price'], color='purple')"
      ],
      "metadata": {
        "id": "z02UajforSlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Вычислить корреляцию - связи между всеми элементами датасета\n",
        "\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "# Визуализировать связи между всеми элементами датасета\n",
        "# Чем теплее оттенок, тем сильнее связь, и наоборот\n",
        "\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')"
      ],
      "metadata": {
        "id": "O-03iejhskZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сделайте выводы по каждой выбранной визуализации:\n",
        "- сбалансированная выборка или нет,\n",
        "- есть связь или зависимость между выбранными данными или нет,\n",
        "- возрастает или убывает сила связи,\n",
        "- есть ли выбросы в данных..."
      ],
      "metadata": {
        "id": "kCsaAaxJBu9-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "   - Выведите наиболее частотные коллокации и слова (возможные методы):\n",
        "     - создайте частотные словари,\n",
        "     - визуализация с помощью облака слов"
      ],
      "metadata": {
        "id": "DBiAHTRWBK9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# пример частотного словаря для одного текста в датасете\n",
        "\n",
        "data = pd.Series(df['Tokens'][50])\n",
        "\n",
        "frequency_dict = data.value_counts().to_dict()\n",
        "\n",
        "frequency_dict"
      ],
      "metadata": {
        "id": "D0JAJMnYCtrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "# облако слов для одного текста\n",
        "\n",
        "wordcloud = WordCloud().generate(df['text'][50])\n",
        "\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Awr-IDQXG_DA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Какие выводы позволяет сделать частотный словарь? Какова практическая значимость такой работы: можно ли создать с ее помощью векторное представление текста, выявить стоп-слова? Что еще можно сделать с частотным словарем и облаком слов?"
      ],
      "metadata": {
        "id": "TF2kveRkHXdf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IV. Векторное представление\n",
        "   - Построить любое векторное представление (ориентируйтесь на свой опыт в Python):\n",
        "     - Bag-of-Words\n",
        "     - TF-IDF\n",
        "     - Word2Vec\n",
        "   - Если с построением векторного представления возникают трудности, выделите такие характеристики текстов:\n",
        "     - минимальная, максимальная, средняя длина текста в датасете..."
      ],
      "metadata": {
        "id": "ZcIa0sGzBF4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# образец двухмерного (для двух предложений) мешка слов\n",
        "\n",
        "df1 = pd.DataFrame(glossaries[0], columns=['word', 'sentence 0'])\n",
        "df2 = pd.DataFrame(glossaries[2], columns=['word', 'sentence 2'])\n",
        "\n",
        "df = df1.merge(df2, on='word')\n",
        "\n",
        "df.columns = ['word', 'sentence 0', 'sentence 1']\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "MFttR-iH9HqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## V. Модель NLP\n",
        "   - Выбрать и применить к данным готовую модель NLP для решения какой-либо задачи:\n",
        "     - анализ тональности,\n",
        "     - классификация,\n",
        "     - суммаризация,\n",
        "     - разметка именованных сущностей,\n",
        "     - разметка синтаксиса или частей речи..."
      ],
      "metadata": {
        "id": "NvicLOn-IKkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# применяем TextBlob для анализа тональности к данным\n",
        "\n",
        "from textblob import TextBlob\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    text = row['text']\n",
        "    sentiment = TextBlob(text)\n",
        "\n",
        "    df.loc[index, 'Polarity'] = sentiment.sentiment.polarity\n",
        "    df.loc[index, 'Subjectivity'] = sentiment.sentiment.subjectivity"
      ],
      "metadata": {
        "id": "bso1gk7-JCwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Оценка результата:\n",
        "     - данные можно визуализировать (например, с помощью матрицы ошибок) или оценить метриками (например, полнота, точность и F-мера)\n",
        "     - вы должны обосновать свой выбор визуализации и метрик оценки"
      ],
      "metadata": {
        "id": "T9UWyEWLJTLw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# визуализация результатов работы модели\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.hist(df['Polarity'], bins=20, edgecolor='black', alpha=0.7)\n",
        "plt.xlabel('Polarity Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Polarity Scores')\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.hist(df['Subjectivity'], bins=20, edgecolor='black', alpha=0.7)\n",
        "plt.xlabel('Subjectivity Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Subjectivity Scores')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QlZO0vFrKKtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VI. Выводы\n",
        "   - Представьте свои рассуждения о проделанной работе:\n",
        "     - с какими трудностями вы столкнулись,\n",
        "     - что нового вы узнали в нашем курсе и в процессе работы над проектом,\n",
        "     - какие выводы сделали для себя, что открыли, что заберете с собой для будущих работ\n",
        "   - Перспективы:\n",
        "     - поделитесь идеями о том, как можно развить ваш проект\n",
        "\n",
        "## VII. Презентация\n",
        "   - Будьте готовы к устной презентации:\n",
        "     - разработайте короткую презентацию (5 слайдов), в которой вы опишете цели, задачи, процесс работы и результаты\n",
        "   - Иллюстрации:\n",
        "     - представьте основные выводы, репрезентативные визуализации\n",
        "\n",
        "## VIII. Загрузка\n",
        "   - Загрузить код и презентацию в свой репозиторий"
      ],
      "metadata": {
        "id": "eT63yT2mKQ7C"
      }
    }
  ]
}